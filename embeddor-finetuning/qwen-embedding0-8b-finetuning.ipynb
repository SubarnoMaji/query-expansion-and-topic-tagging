{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaH100","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"sourceType":"competition"},{"sourceId":14381021,"sourceType":"datasetVersion","datasetId":9184148}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"TOPIC_HIERARCHY = {\n    \"Politics\": [\"India\", \"UK\", \"USA\", \"China\", \"Russia\", \"Global\"],\n    \"Sports\": [\"Cricket\", \"Football\", \"Basketball\", \"Tennis\", \"Olympics\"],\n    \"Technology\": [\"Artificial Intelligence\", \"Machine Learning\", \"Software Development\", \"Cybersecurity\", \"Blockchain\"],\n    \"Business\": [\"Startups\", \"Finance\", \"Stock Market\", \"Economy\", \"E-commerce\"],\n    \"Entertainment\": [\"Movies\", \"TV Shows\", \"Music\", \"Celebrities\", \"OTT Platforms\"],\n    \"Science\": [\"Physics\", \"Biology\", \"Space\", \"Climate\", \"Research\"],\n    \"Health\": [\"Fitness\", \"Nutrition\", \"Mental Health\", \"Diseases\", \"Medicine\"],\n    \"Education\": [\"Exams\", \"Universities\", \"Online Courses\", \"Careers\", \"Research\"],\n    \"General\": [\"Chitchat\", \"Greetings\", \"Meta\", \"Clarification\", \"Other\"]\n}\n\n\ndef flatten_messages(messages):\n    parts = []\n    for m in messages:\n        parts.append(f\"{m['role'].capitalize()}: {m['content'].strip()}\")\n    return \"\\n\".join(parts)\n    \nID2LABEL = {}\nidx = 0\nfor l1, l2_list in TOPIC_HIERARCHY.items():\n    for l2 in l2_list:\n        ID2LABEL[idx] = (l1, l2)\n        idx += 1\n\nLEVEL2_LABEL2ID = {v: k for k, v in ID2LABEL.items()}\nNUM_CLASSES = len(LEVEL2_LABEL2ID)\n\nprint(f\"Number of classes: {NUM_CLASSES}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:10.804314Z","iopub.execute_input":"2026-01-03T12:36:10.804656Z","iopub.status.idle":"2026-01-03T12:36:10.809859Z","shell.execute_reply.started":"2026-01-03T12:36:10.804638Z","shell.execute_reply":"2026-01-03T12:36:10.809448Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 46\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\nimport torch\nfrom torch.utils.data import Dataset\n\nclass TopicHierarchyDataset(Dataset):\n    def __init__(self, jsonl_path):\n        self.samples = []\n\n        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                data = json.loads(line)\n\n                text = flatten_messages(data[\"messages\"])\n\n                l1 = data[\"labels\"][\"topic\"][\"level_1\"]\n                l2 = data[\"labels\"][\"topic\"][\"level_2\"]\n\n                label_id = LEVEL2_LABEL2ID[(l1, l2)]\n\n                self.samples.append({\n                    \"text\": text,\n                    \"label\": label_id\n                })\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        item = self.samples[idx]\n        return {\n            \"text\": item[\"text\"],\n            \"label\": torch.tensor(item[\"label\"], dtype=torch.long)\n        }\n\ndef collate_fn(batch):\n    return {\n        \"texts\": [b[\"text\"] for b in batch],\n        \"labels\": torch.stack([b[\"label\"] for b in batch]),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:18.022372Z","iopub.execute_input":"2026-01-03T12:36:18.022744Z","iopub.status.idle":"2026-01-03T12:36:18.027509Z","shell.execute_reply.started":"2026-01-03T12:36:18.022727Z","shell.execute_reply":"2026-01-03T12:36:18.027104Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nimport torch\n\ndataset = TopicHierarchyDataset(\"/kaggle/input/finaltagging/data1.jsonl\")\n\ntrain_ratio = 0.8\nval_ratio = 0.1\ntest_ratio = 0.1\n\ntotal_size = len(dataset)\ntrain_size = int(train_ratio * total_size)\nval_size = int(val_ratio * total_size)\ntest_size = total_size - train_size - val_size\n\ngenerator = torch.Generator().manual_seed(42)\n\ntrain_ds, val_ds, test_ds = random_split(\n    dataset,\n    [train_size, val_size, test_size],\n    generator=generator\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:24.104214Z","iopub.execute_input":"2026-01-03T12:36:24.104782Z","iopub.status.idle":"2026-01-03T12:36:24.170128Z","shell.execute_reply.started":"2026-01-03T12:36:24.104765Z","shell.execute_reply":"2026-01-03T12:36:24.169704Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_loader = DataLoader(\n    train_ds,\n    batch_size=8,\n    shuffle=True,\n    collate_fn=collate_fn\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=8,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=8,\n    shuffle=False,\n    collate_fn=collate_fn\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:26.511494Z","iopub.execute_input":"2026-01-03T12:36:26.511721Z","iopub.status.idle":"2026-01-03T12:36:26.515296Z","shell.execute_reply.started":"2026-01-03T12:36:26.511705Z","shell.execute_reply":"2026-01-03T12:36:26.514880Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(\"Train:\", len(train_ds))\nprint(\"Val:\", len(val_ds))\nprint(\"Test:\", len(test_ds))\n\nbatch = next(iter(train_loader))\nprint(batch.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:30.504639Z","iopub.execute_input":"2026-01-03T12:36:30.504856Z","iopub.status.idle":"2026-01-03T12:36:30.549456Z","shell.execute_reply.started":"2026-01-03T12:36:30.504840Z","shell.execute_reply":"2026-01-03T12:36:30.549019Z"}},"outputs":[{"name":"stdout","text":"Train: 404\nVal: 50\nTest: 52\ndict_keys(['texts', 'labels'])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"batch = next(iter(train_loader))\n\nprint(\"===== BATCH SAMPLE =====\")\nprint(batch[\"texts\"][0])\nprint(\"\\n===== LABEL =====\")\n\nlabel_id = batch[\"labels\"][0].item()\nprint(\"Label ID:\", label_id)\nprint(\"Decoded Label:\", ID2LABEL[label_id])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:31.246918Z","iopub.execute_input":"2026-01-03T12:36:31.247227Z","iopub.status.idle":"2026-01-03T12:36:31.263667Z","shell.execute_reply.started":"2026-01-03T12:36:31.247211Z","shell.execute_reply":"2026-01-03T12:36:31.263247Z"}},"outputs":[{"name":"stdout","text":"===== BATCH SAMPLE =====\nUser: Hey there! How's your day going so far?\nAssistant: It's been pretty good, thanks for asking! Just trying to clear my inbox. How about yours?\nUser: Mine's been a bit hectic, but I'm looking forward to unwinding tonight.\nAssistant: Oh, sounds like a good plan. Do you have anything fun lined up?\nUser: Yeah, I was thinking of finally watching that new sci-fi movie everyone's raving about. My friend Sarah mentioned it earlier.\nAssistant: The one with the incredible special effects? I've heard it's epic. Are you going to watch it by yourself?\nUser: Nah, she's joining me.\n\n===== LABEL =====\nLabel ID: 41\nDecoded Label: ('General', 'Chitchat')\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel\n\nMODEL_NAME = \"Qwen/Qwen3-Embedding-0.6B\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nbase_model = AutoModel.from_pretrained(MODEL_NAME)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:36:33.601021Z","iopub.execute_input":"2026-01-03T12:36:33.601645Z","iopub.status.idle":"2026-01-03T12:37:05.918697Z","shell.execute_reply.started":"2026-01-03T12:36:33.601625Z","shell.execute_reply":"2026-01-03T12:37:05.918209Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de61d2b2c2214f7680eb32f3148fa801"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1798eb574f13444f8a514fecffae7337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"985449f4c9794f019422640aadc138e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c52f34e6054275b1f90f688e456725"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a5ff95681514b0fa53871a1e7a9d755"}},"metadata":{}},{"name":"stderr","text":"2026-01-03 12:36:48.162987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767443808.570664     106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767443808.665242     106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767443809.669173     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767443809.669203     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767443809.669205     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767443809.669207     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63aec16efe2c41c0a1f5b3c4571bc002"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"class QwenTopicClassifier(nn.Module):\n    def __init__(self, base_model, num_classes):\n        super().__init__()\n        self.encoder = base_model\n        hidden_size = base_model.config.hidden_size\n\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size, num_classes)\n        )\n\n    def mean_pool(self, last_hidden_state, attention_mask):\n        mask = attention_mask.unsqueeze(-1).float()\n        summed = torch.sum(last_hidden_state * mask, dim=1)\n        counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n        return summed / counts\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=True\n        )\n\n        pooled = self.mean_pool(outputs.last_hidden_state, attention_mask)\n        logits = self.classifier(pooled)\n\n        loss = None\n        if labels is not None:\n            loss = nn.CrossEntropyLoss()(logits, labels)\n\n        return {\n            \"loss\": loss,\n            \"logits\": logits\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:37:39.750416Z","iopub.execute_input":"2026-01-03T12:37:39.751185Z","iopub.status.idle":"2026-01-03T12:37:39.755724Z","shell.execute_reply.started":"2026-01-03T12:37:39.751163Z","shell.execute_reply":"2026-01-03T12:37:39.755305Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"NUM_CLASSES = 46\n\nmodel = QwenTopicClassifier(\n    base_model=base_model,\n    num_classes=NUM_CLASSES\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:37:42.425650Z","iopub.execute_input":"2026-01-03T12:37:42.425867Z","iopub.status.idle":"2026-01-03T12:37:42.881843Z","shell.execute_reply.started":"2026-01-03T12:37:42.425850Z","shell.execute_reply":"2026-01-03T12:37:42.881423Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"QwenTopicClassifier(\n  (encoder): Qwen3Model(\n    (embed_tokens): Embedding(151669, 1024)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen3DecoderLayer(\n        (self_attn): Qwen3Attention(\n          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n        )\n        (mlp): Qwen3MLP(\n          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n      )\n    )\n    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n    (rotary_emb): Qwen3RotaryEmbedding()\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=1024, out_features=46, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"def tokenize_batch(batch):\n    enc = tokenizer(\n        batch[\"texts\"],\n        padding=True,\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )\n    enc[\"labels\"] = batch[\"labels\"]\n    return enc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:37:45.698523Z","iopub.execute_input":"2026-01-03T12:37:45.699105Z","iopub.status.idle":"2026-01-03T12:37:45.701726Z","shell.execute_reply.started":"2026-01-03T12:37:45.699087Z","shell.execute_reply":"2026-01-03T12:37:45.701330Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from torch.optim import AdamW\nfrom tqdm import tqdm\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\nmodel.train()\n\nfor epoch in range(3):\n    total_loss = 0\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        batch = tokenize_batch(batch)\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        optimizer.zero_grad()\n        outputs = model(**batch)\n        loss = outputs[\"loss\"]\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:37:48.114033Z","iopub.execute_input":"2026-01-03T12:37:48.114539Z","iopub.status.idle":"2026-01-03T12:38:14.731535Z","shell.execute_reply.started":"2026-01-03T12:37:48.114520Z","shell.execute_reply":"2026-01-03T12:38:14.731059Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 51/51 [00:09<00:00,  5.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 1.8210\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 51/51 [00:08<00:00,  6.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.1500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 51/51 [00:08<00:00,  6.13it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.0340\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"model.eval()\ncorrect, total = 0, 0\n\nwith torch.no_grad():\n    for batch in val_loader:\n        batch = tokenize_batch(batch)\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        preds = outputs[\"logits\"].argmax(dim=-1)\n\n        correct += (preds == batch[\"labels\"]).sum().item()\n        total += batch[\"labels\"].size(0)\n\nprint(\"Validation Accuracy:\", correct / total)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:38:18.192095Z","iopub.execute_input":"2026-01-03T12:38:18.192614Z","iopub.status.idle":"2026-01-03T12:38:18.578361Z","shell.execute_reply.started":"2026-01-03T12:38:18.192596Z","shell.execute_reply":"2026-01-03T12:38:18.577861Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.98\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model.eval()\n\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = tokenize_batch(batch)\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(**batch)\n        preds = outputs[\"logits\"].argmax(dim=-1)\n\n        correct += (preds == batch[\"labels\"]).sum().item()\n        total += batch[\"labels\"].size(0)\n\ntest_accuracy = correct / total\nprint(f\"Test Accuracy: {correct}/{total} : {test_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-03T12:40:39.008177Z","iopub.execute_input":"2026-01-03T12:40:39.008711Z","iopub.status.idle":"2026-01-03T12:40:39.379301Z","shell.execute_reply.started":"2026-01-03T12:40:39.008694Z","shell.execute_reply":"2026-01-03T12:40:39.378847Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 50/52 : 0.9615\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}